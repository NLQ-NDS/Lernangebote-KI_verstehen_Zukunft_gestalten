WEBVTT

1
00:00:06.640 --> 00:00:08.400
Willkommen zu unserem Kurs über

2
00:00:08.400 --> 00:00:10.920
Ethik und Verantwortung im Kontext

3
00:00:10.920 --> 00:00:13.440
von künstlicher Intelligenz.

4
00:00:13.440 --> 00:00:15.040
In diesem Kurs betrachten

5
00:00:15.040 --> 00:00:16.560
wir das Zusammenspiel von

6
00:00:16.560 --> 00:00:18.080
Technologie und Gesellschaft.

7
00:00:21.200 --> 00:00:22.560
Zunächst klären wir die

8
00:00:23.280 --> 00:00:25.400
künstliche Intelligenz bezeichnet

9
00:00:25.400 --> 00:00:26.960
softwarebasierte Systeme

10
00:00:27.630 --> 00:00:29.510
selbstständig Aufgaben ausführen

11
00:00:29.510 --> 00:00:31.270
und dabei Vorhersagen oder

12
00:00:31.270 --> 00:00:32.830
Entscheidungen erzeugen können.

13
00:00:33.870 --> 00:00:35.350
Einfache Beispiele sind

14
00:00:35.350 --> 00:00:36.990
Sprachassistenten oder

15
00:00:36.990 --> 00:00:38.870
Algorithmen, die Inhalte in

16
00:00:38.870 --> 00:00:40.350
sozialen Medien filtern.

17
00:00:41.950 --> 00:00:43.550
Ethik stellt in diesem

18
00:00:43.550 --> 00:00:45.550
Zusammenhang die Frage, was

19
00:00:45.550 --> 00:00:46.990
verantwortungsbewusstes

20
00:00:46.990 --> 00:00:48.550
Handeln im Umgang mit solchen

21
00:00:48.550 --> 00:00:50.030
Technologien bedeutet.

22
00:00:50.910 --> 00:00:52.550
Denn letztlich sind wir als

23
00:00:52.550 --> 00:00:54.910
Menschen sowohl in der Schule

24
00:00:54.910 --> 00:00:56.510
als auch in der Verwaltung

25
00:00:56.510 --> 00:00:57.750
verantwortlich für die

26
00:00:57.750 --> 00:00:59.950
Auswirkungen von KI Systemen.

27
00:01:00.750 --> 00:01:03.350
Technologien wie KI beeinflussen

28
00:01:03.350 --> 00:01:05.069
gesellschaftliche Prozesse

29
00:01:05.069 --> 00:01:06.350
und gleichzeitig

30
00:01:06.350 --> 00:01:08.070
wirken gesellschaftliche Werte

31
00:01:08.070 --> 00:01:10.550
darauf zurück, wie KI entwickelt

32
00:01:10.550 --> 00:01:11.870
und eingesetzt wird.

33
00:01:12.750 --> 00:01:14.430
Der Medientheoretiker John

34
00:01:14.430 --> 00:01:17.710
Culkin sagte bereits 1967

35
00:01:18.350 --> 00:01:20.690
wir formen unsere Werkzeuge,

36
00:01:20.690 --> 00:01:22.290
danach formen sie uns.

37
00:01:24.290 --> 00:01:25.970
KI ist also nicht nur ein

38
00:01:25.970 --> 00:01:27.970
technisches Hilfsmittel, sondern

39
00:01:27.970 --> 00:01:29.810
ein gesellschaftlicher Faktor.

40
00:01:30.930 --> 00:01:32.330
Vor diesem Hintergrund schauen

41
00:01:32.330 --> 00:01:33.730
wir uns in diesem Kurs an,

42
00:01:33.730 --> 00:01:35.770
wie KI den Schulalltag und

43
00:01:35.770 --> 00:01:37.890
Verwaltungsprozesse verändern wird

44
00:01:37.890 --> 00:01:39.290
und welche ethischen

45
00:01:39.290 --> 00:01:40.930
Fragen sich daraus ergeben.

46
00:01:41.810 --> 00:01:42.770
Dieser Kurs ist

47
00:01:42.770 --> 00:01:44.530
einsteigerfreundlich.

48
00:01:44.530 --> 00:01:45.890
Es geht nicht technische

49
00:01:45.890 --> 00:01:47.440
Details, sondern

50
00:01:47.440 --> 00:01:49.320
grundlegende Zusammenhänge, die

51
00:01:49.320 --> 00:01:51.040
wir praxisnah erläutern.

52
00:01:51.920 --> 00:01:54.120
Unser Ziel ist es, die Chancen und

53
00:01:54.120 --> 00:01:55.960
Risiken von KI in Schule und

54
00:01:55.960 --> 00:01:57.760
Verwaltung verständlich zu machen.

55
00:01:59.120 --> 00:02:00.720
Warum ist das Thema wichtig?

56
00:02:03.920 --> 00:02:05.320
KI ist bereits im

57
00:02:05.320 --> 00:02:06.640
Alltag angekommen.

58
00:02:06.640 --> 00:02:08.280
Schülerinnen und Schüler nutzen

59
00:02:08.280 --> 00:02:10.840
ChatGPT und ähnliche Tools,

60
00:02:10.840 --> 00:02:12.880
Referate vorzubereiten oder

61
00:02:12.880 --> 00:02:14.320
Hausaufgaben zu erledigen.

62
00:02:15.150 --> 00:02:16.390
Auch in der Verwaltung können

63
00:02:16.390 --> 00:02:18.110
KI Systeme helfen,

64
00:02:18.110 --> 00:02:20.270
Anfragen zu beantworten oder

65
00:02:20.270 --> 00:02:22.270
Prozesse zu strukturieren.

66
00:02:22.270 --> 00:02:23.390
Lehrkräfte und

67
00:02:23.390 --> 00:02:25.670
Verwaltungsmitarbeitende begegnen

68
00:02:25.670 --> 00:02:28.430
KI zunehmend im Berufsalltag.

69
00:02:28.430 --> 00:02:29.870
Daher ist es wichtig,

70
00:02:29.870 --> 00:02:31.990
die Funktionsweise zu verstehen

71
00:02:31.990 --> 00:02:34.350
und kompetent damit umzugehen.

72
00:02:35.230 --> 00:02:36.790
KI bringt ethische

73
00:02:36.790 --> 00:02:38.590
Herausforderungen mit sich.

74
00:02:38.590 --> 00:02:40.230
KI entscheidet nicht aus

75
00:02:40.230 --> 00:02:41.590
freiem Willen, sondern

76
00:02:41.590 --> 00:02:42.830
auf Basis von Daten.

77
00:02:43.490 --> 00:02:45.170
Verzerrungen in diesen Daten,

78
00:02:45.170 --> 00:02:47.290
sogenannter Bias, können

79
00:02:47.290 --> 00:02:49.570
Ungerechtigkeiten verstärken.

80
00:02:49.570 --> 00:02:50.210
Z.B.

81
00:02:50.210 --> 00:02:51.250
funktionieren manche

82
00:02:51.250 --> 00:02:52.890
Gesichtserkennungen bei bestimmten

83
00:02:52.890 --> 00:02:54.930
Personengruppen schlechter

84
00:02:54.930 --> 00:02:57.970
oder KI Systeme werten Aufsätze

85
00:02:57.970 --> 00:02:59.890
von mehrsprachigen Lernenden

86
00:02:59.890 --> 00:03:01.410
systematisch anders.

87
00:03:02.010 --> 00:03:03.530
Solche Effekte zu erkennen

88
00:03:03.530 --> 00:03:05.010
und auszugleichen,

89
00:03:05.010 --> 00:03:06.730
braucht es medienethische

90
00:03:06.730 --> 00:03:08.290
Kompetenz bei Lehrkräften

91
00:03:08.290 --> 00:03:09.570
und Verwaltungskräften.

92
00:03:10.760 --> 00:03:12.840
Rollen und Aufgaben verändern sich.

93
00:03:13.400 --> 00:03:15.280
KI kann den Berufsalltag

94
00:03:15.280 --> 00:03:17.080
unterstützen, z.B.

95
00:03:17.080 --> 00:03:18.440
durch automatisierte

96
00:03:18.440 --> 00:03:20.280
Korrekturvorschläge oder

97
00:03:20.280 --> 00:03:21.880
vorsortierte Anfragen.

98
00:03:22.600 --> 00:03:24.120
Gleichzeitig müssen

99
00:03:24.120 --> 00:03:26.200
Zuständigkeiten klar bleiben.

100
00:03:26.200 --> 00:03:27.720
Letztlich tragen Menschen

101
00:03:27.720 --> 00:03:28.760
die Verantwortung.

102
00:03:29.320 --> 00:03:30.320
Lehrkräfte und

103
00:03:30.320 --> 00:03:32.480
Verwaltungsmitarbeitende brauchen

104
00:03:32.480 --> 00:03:35.360
neue Kompetenzen, mit KI sinnvoll

105
00:03:35.360 --> 00:03:37.000
und pflichtbewusst umzugehen.

106
00:03:38.220 --> 00:03:39.900
KI wirkt bereits heute auf

107
00:03:39.900 --> 00:03:41.900
Schule und Verwaltung ein.

108
00:03:41.900 --> 00:03:43.820
Wer die Grundlagen versteht,

109
00:03:43.820 --> 00:03:46.540
kann Chancen gezielt nutzen, etwa

110
00:03:46.540 --> 00:03:48.980
zur individuellen Förderung oder

111
00:03:48.980 --> 00:03:51.180
zur automatisierten Vorsortierung

112
00:03:51.180 --> 00:03:53.580
von Anträgen, und gleichzeitig

113
00:03:53.580 --> 00:03:55.660
Risiken aktiv begegnen.

114
00:03:56.380 --> 00:03:58.940
Ziel ist ein reflektierter,

115
00:03:58.940 --> 00:04:01.340
handlungsfähiger Umgang mit KI

116
00:04:01.340 --> 00:04:02.940
im eigenen Arbeitsumfeld.

117
00:04:06.950 --> 00:04:08.670
Folgende Aspekte werden wir uns in

118
00:04:08.670 --> 00:04:13.630
diesem Kurs anschauen in diesem

119
00:04:13.630 --> 00:04:15.030
Kurs vertiefen wir drei

120
00:04:15.030 --> 00:04:16.829
Themenbereiche, die helfen

121
00:04:16.829 --> 00:04:18.709
sollen, den ethischen Umgang mit

122
00:04:18.709 --> 00:04:20.870
KI in Schule und Verwaltung

123
00:04:20.870 --> 00:04:22.150
besser zu verstehen.

124
00:04:23.030 --> 00:04:24.590
Wir beginnen mit dem Blick auf

125
00:04:24.590 --> 00:04:26.790
die Gesellschaft insgesamt.

126
00:04:26.790 --> 00:04:28.510
Wie verändert KI unsere

127
00:04:28.510 --> 00:04:29.940
Wahrnehmung, unsere

128
00:04:29.940 --> 00:04:31.700
Informationsauswahl

129
00:04:31.700 --> 00:04:33.460
und bestehende Rollenbilder?

130
00:04:34.020 --> 00:04:35.620
Wir zeigen, wie Algorithmen

131
00:04:35.620 --> 00:04:37.860
Informationen personalisieren

132
00:04:37.860 --> 00:04:39.020
und dadurch unser

133
00:04:39.020 --> 00:04:41.220
Weltbild beeinflussen.

134
00:04:41.220 --> 00:04:43.300
Außerdem betrachten wir, wie sich

135
00:04:43.300 --> 00:04:45.300
Machtverhältnisse verschieben,

136
00:04:45.300 --> 00:04:47.860
wenn KI zunehmend an politischen,

137
00:04:47.860 --> 00:04:49.580
wirtschaftlichen und kulturellen

138
00:04:49.580 --> 00:04:51.140
Entscheidungen beteiligt ist.

139
00:04:52.180 --> 00:04:54.020
Im zweiten Teil geht es

140
00:04:54.020 --> 00:04:55.620
konkrete Anwendungsfelder

141
00:04:55.620 --> 00:04:56.820
in Schule und Verwaltung.

142
00:04:57.410 --> 00:04:59.770
Wir wo kommt KI heute

143
00:04:59.770 --> 00:05:01.250
schon zum Einsatz?

144
00:05:01.250 --> 00:05:03.490
Was verändert sich für Lehrkräfte,

145
00:05:03.490 --> 00:05:05.090
Schülerinnen und Schüler

146
00:05:05.090 --> 00:05:06.930
und Verwaltungsmitarbeitende?

147
00:05:07.490 --> 00:05:10.050
Wir besprechen Chancen und Risiken,

148
00:05:10.050 --> 00:05:11.410
etwa individuelle

149
00:05:11.410 --> 00:05:13.450
Förderung, aber auch mögliche

150
00:05:13.450 --> 00:05:15.090
Verzerrungen bei Bewertungen

151
00:05:15.090 --> 00:05:16.850
oder Datenschutzproblemen.

152
00:05:17.890 --> 00:05:19.290
Zum Schluss richten wir

153
00:05:19.290 --> 00:05:21.090
den Blick nach vorn.

154
00:05:21.090 --> 00:05:22.210
Welche gesetzlichen

155
00:05:22.210 --> 00:05:23.650
Regelungen gibt es bereits?

156
00:05:24.190 --> 00:05:24.710
Z.B.

157
00:05:24.710 --> 00:05:26.990
durch den EU AI Act?

158
00:05:27.550 --> 00:05:29.150
Welche Verantwortung tragen

159
00:05:29.150 --> 00:05:30.710
Politik, Verwaltung und

160
00:05:30.710 --> 00:05:32.510
Schulen bei der Einführung

161
00:05:32.510 --> 00:05:34.270
und Nutzung von KI?

162
00:05:34.270 --> 00:05:36.350
Und wie kann KI so gestaltet

163
00:05:36.350 --> 00:05:37.790
werden, dass sie unseren

164
00:05:37.790 --> 00:05:39.550
Werten entspricht und konkrete

165
00:05:39.550 --> 00:05:40.910
Verbesserungen ermöglicht?

166
00:05:41.710 --> 00:05:43.750
Dazu geben wir praxisnahe

167
00:05:43.750 --> 00:05:45.950
Denkanstöße zur Reflexion

168
00:05:45.950 --> 00:05:47.790
im eigenen Arbeitsumfeld.

169
00:05:48.750 --> 00:05:50.470
Abschließend folgen noch ein

170
00:05:50.470 --> 00:05:52.610
Fazit mit Handlungsempfehlungen

171
00:05:52.610 --> 00:05:53.610
und ein Ausblick auf

172
00:05:53.610 --> 00:05:55.170
zukünftige Entwicklungen.

173
00:05:57.410 --> 00:05:59.370
KI beeinflusst unsere Gesellschaft

174
00:05:59.370 --> 00:06:00.610
auf vielfältige Weise.

175
00:06:01.170 --> 00:06:02.290
In diesem Abschnitt

176
00:06:02.290 --> 00:06:03.970
betrachten wir drei zentrale

177
00:06:03.970 --> 00:06:05.330
Wirkbereiche genauer.

178
00:06:08.050 --> 00:06:09.970
Wir beginnen mit der KI als

179
00:06:09.970 --> 00:06:11.330
gesellschaftliche Kraft.

180
00:06:15.170 --> 00:06:16.130
Wahrnehmung und

181
00:06:16.130 --> 00:06:18.530
Wirklichkeitskonstruktion durch KI

182
00:06:19.360 --> 00:06:21.320
künstliche Intelligenz begegnet

183
00:06:21.320 --> 00:06:22.480
uns häufig auch in Form

184
00:06:22.480 --> 00:06:23.880
von Algorithmen, die

185
00:06:23.880 --> 00:06:25.440
Informationen sortieren.

186
00:06:26.960 --> 00:06:28.480
Sie entscheiden z.B.

187
00:06:28.480 --> 00:06:30.240
welche Beiträge in sozialen

188
00:06:30.240 --> 00:06:32.160
Netzwerken angezeigt werden.

189
00:06:32.160 --> 00:06:33.600
Dadurch entsteht für jede

190
00:06:33.600 --> 00:06:35.039
Person eine individuelle

191
00:06:35.039 --> 00:06:36.320
Online Wirklichkeit.

192
00:06:37.760 --> 00:06:39.520
Diese Personalisierung kann

193
00:06:39.520 --> 00:06:41.320
hilfreich sein, birgt aber

194
00:06:41.320 --> 00:06:42.680
auch Risiken wie die Bildung

195
00:06:42.680 --> 00:06:44.440
von Echokammern oder die

196
00:06:44.440 --> 00:06:46.080
Verstärkung von Vorurteilen.

197
00:06:47.800 --> 00:06:50.360
Algorithmen sind nicht objektiv.

198
00:06:50.360 --> 00:06:51.840
Sie spiegeln Interessen und

199
00:06:51.840 --> 00:06:53.640
Entscheidungen wider, die in ihre

200
00:06:53.640 --> 00:06:55.560
Programmierung eingeflossen sind.

201
00:06:57.160 --> 00:06:59.600
Gerade weil KI unsere digitale

202
00:06:59.600 --> 00:07:01.480
Wirklichkeit mitgestaltet, ist

203
00:07:01.480 --> 00:07:03.600
es entscheidend, diese Einflüsse

204
00:07:03.600 --> 00:07:06.680
bewusst zu Welche Inhalte

205
00:07:06.680 --> 00:07:08.200
sehe ich und welche nicht?

206
00:07:08.920 --> 00:07:10.200
Warum schlägt mir ein

207
00:07:10.200 --> 00:07:12.450
Algorithmus bestimmte Beiträge,

208
00:07:12.450 --> 00:07:14.050
Videos oder Produkte vor?

209
00:07:15.730 --> 00:07:17.450
Diese Fragen helfen, den

210
00:07:17.450 --> 00:07:19.490
Filtermechanismen der Algorithmen

211
00:07:19.490 --> 00:07:21.650
nicht passiv ausgeliefert zu sein.

212
00:07:23.250 --> 00:07:25.050
Medienethische Bildung spielt

213
00:07:25.050 --> 00:07:27.090
dabei eine zentrale Rolle.

214
00:07:27.090 --> 00:07:28.449
Lehrkräfte sollten mit

215
00:07:28.449 --> 00:07:30.050
Schülerinnen und Schülern über

216
00:07:30.050 --> 00:07:32.050
digitale Wahrnehmung sprechen,

217
00:07:32.050 --> 00:07:32.970
etwa durch den

218
00:07:32.970 --> 00:07:34.810
Vergleich von Suchergebnissen,

219
00:07:34.810 --> 00:07:36.850
das Enttarnen von Echokammern

220
00:07:36.850 --> 00:07:38.250
oder die Analyse von

221
00:07:38.250 --> 00:07:39.570
Empfehlungsalgorithmen.

222
00:07:40.770 --> 00:07:41.970
In der Verwaltung kann das

223
00:07:41.970 --> 00:07:43.690
bedeuten, algorithmische

224
00:07:43.690 --> 00:07:44.570
Vorschläge nicht

225
00:07:44.570 --> 00:07:46.290
unreflektiert zu übernehmen,

226
00:07:46.290 --> 00:07:48.290
sondern zu prüfen, welche

227
00:07:48.290 --> 00:07:49.570
Parameter zur Entscheidung

228
00:07:49.570 --> 00:07:51.050
geführt haben und ob

229
00:07:51.050 --> 00:07:52.770
Alternativen denkbar sind.

230
00:07:54.290 --> 00:07:56.290
Kritische Medienkompetenz heißt,

231
00:07:56.290 --> 00:07:59.010
also nicht nur wissen, dass KI unsere

232
00:07:59.010 --> 00:08:01.090
Wahrnehmung beeinflusst, sondern

233
00:08:01.090 --> 00:08:03.130
aktiv zu fragen, wie das

234
00:08:03.130 --> 00:08:05.500
geschieht und wem es nützt.

235
00:08:05.500 --> 00:08:07.300
So entsteht ein bewusster Umgang

236
00:08:07.300 --> 00:08:09.420
mit digital vermittelter Realität.

237
00:08:12.620 --> 00:08:14.180
Soziale Rollenbilder und

238
00:08:14.180 --> 00:08:16.180
Verzerrungen KI Systeme

239
00:08:16.180 --> 00:08:17.820
basieren auf Trainingsdaten,

240
00:08:17.820 --> 00:08:18.700
die aus unserer

241
00:08:18.700 --> 00:08:20.220
gesellschaftlichen Realität

242
00:08:20.220 --> 00:08:21.659
stammen und damit auch

243
00:08:21.659 --> 00:08:22.700
auf deren Normen,

244
00:08:22.700 --> 00:08:24.700
Vorurteilen und Klischees.

245
00:08:26.140 --> 00:08:28.020
Diese Daten spiegeln oft

246
00:08:28.020 --> 00:08:29.860
unausgesprochene gesellschaftliche

247
00:08:29.860 --> 00:08:31.900
Erwartungen oder bestehende

248
00:08:31.900 --> 00:08:33.620
Ungleichheiten wider.

249
00:08:33.620 --> 00:08:35.419
Wenn eine KI aus diesen Daten

250
00:08:35.419 --> 00:08:36.940
lernt, kann sie solche

251
00:08:36.940 --> 00:08:38.419
Muster nicht nur übernehmen,

252
00:08:38.419 --> 00:08:39.940
sondern auch verstärken.

253
00:08:41.539 --> 00:08:43.980
So reproduzieren KI gestützte

254
00:08:43.980 --> 00:08:45.380
Anwendungen mitunter

255
00:08:45.380 --> 00:08:47.260
stereotype Vorstellungen über

256
00:08:47.260 --> 00:08:49.380
Geschlechterrollen, Herkunft,

257
00:08:49.380 --> 00:08:51.220
Berufsbilder oder Alter.

258
00:08:51.860 --> 00:08:53.020
Ein bekanntes Beispiel

259
00:08:53.020 --> 00:08:54.900
ist die Bildersuche.

260
00:08:54.900 --> 00:08:56.590
Gibt man Begriffe wie

261
00:08:56.590 --> 00:08:57.790
Schulmädchen ein,

262
00:08:57.790 --> 00:08:59.910
erscheinen häufig sexualisierte

263
00:08:59.910 --> 00:09:00.990
Darstellungen,

264
00:09:00.990 --> 00:09:02.830
beim Begriff Schuljunge

265
00:09:02.830 --> 00:09:04.830
hingegen neutrale Bilder.

266
00:09:05.390 --> 00:09:07.350
Solche Verzerrungen entstehen,

267
00:09:07.350 --> 00:09:08.510
weil die Algorithmen

268
00:09:08.510 --> 00:09:10.190
die Häufigkeit und Relevanz

269
00:09:10.190 --> 00:09:11.030
von Darstellungen

270
00:09:11.030 --> 00:09:13.110
statistisch gewichtet, ohne

271
00:09:13.110 --> 00:09:14.510
zwischen problematischen

272
00:09:14.510 --> 00:09:16.190
und angemessenen Inhalten

273
00:09:16.190 --> 00:09:17.070
zu unterscheiden.

274
00:09:18.670 --> 00:09:20.830
Wenn solche Darstellungen durch KI

275
00:09:20.830 --> 00:09:23.180
Systeme weiterverbreitet oder als

276
00:09:23.180 --> 00:09:25.460
normal ausgegeben werden, prägen

277
00:09:25.460 --> 00:09:27.460
sie aktiv unser gesellschaftliches

278
00:09:27.460 --> 00:09:29.940
Verständnis von Rollenbildern mit.

279
00:09:29.940 --> 00:09:32.140
Insbesondere dort, wo Nutzende

280
00:09:32.140 --> 00:09:33.420
kaum hinterfragen, wie

281
00:09:33.420 --> 00:09:35.140
Inhalte zustande kommen.

282
00:09:36.420 --> 00:09:38.220
Doch die Problematik geht über

283
00:09:38.220 --> 00:09:40.180
Bilddarstellungen hinaus.

284
00:09:40.180 --> 00:09:41.580
Auch Sprachmodelle oder

285
00:09:41.580 --> 00:09:43.700
Empfehlungssysteme neigen dazu,

286
00:09:43.700 --> 00:09:45.620
bestehende Ungleichverteilungen

287
00:09:45.620 --> 00:09:47.820
zu stabilisieren, z.B.

288
00:09:47.820 --> 00:09:49.830
bei Berufsempfehlungen, bei

289
00:09:49.830 --> 00:09:51.870
Werbung oder bei automatisierten

290
00:09:51.870 --> 00:09:53.550
Bewerbungsvorsortierungen.

291
00:09:54.990 --> 00:09:56.710
Deshalb fordern Fachleute aus

292
00:09:56.710 --> 00:09:58.310
Informatik, Ethik und

293
00:09:58.310 --> 00:10:00.030
Sozialwissenschaften, dass

294
00:10:00.030 --> 00:10:02.270
Trainingsdaten sorgfältig geprüft,

295
00:10:02.270 --> 00:10:04.750
diverser gestaltet und transparent

296
00:10:04.750 --> 00:10:05.950
dokumentiert werden.

297
00:10:06.510 --> 00:10:08.710
Nur so lässt sich verhindern, dass

298
00:10:08.710 --> 00:10:10.710
die Stereotype der Vergangenheit

299
00:10:10.710 --> 00:10:12.670
unkritisch in die digitale

300
00:10:12.670 --> 00:10:14.030
Zukunft verlängert werden.

301
00:10:15.800 --> 00:10:17.160
Gleichzeitig braucht es auch

302
00:10:17.160 --> 00:10:18.400
gesellschaftliche Debatten

303
00:10:18.400 --> 00:10:19.040
darüber,

304
00:10:19.040 --> 00:10:20.960
welche Wirklichkeitsbilder wir in

305
00:10:20.960 --> 00:10:22.760
digitalen Systemen abgebildet

306
00:10:22.760 --> 00:10:24.600
sehen wollen und welche nicht.

307
00:10:28.040 --> 00:10:30.120
Machtverschiebungen durch KI

308
00:10:31.240 --> 00:10:33.480
KI wird überwiegend von großen

309
00:10:33.480 --> 00:10:35.800
Technologiekonzernen entwickelt.

310
00:10:35.800 --> 00:10:37.520
Diese verfügen über enorme

311
00:10:37.520 --> 00:10:39.480
Datenmengen und Ressourcen.

312
00:10:39.480 --> 00:10:40.600
Daraus ergeben sich

313
00:10:40.600 --> 00:10:42.570
wirtschaftliche und und politische

314
00:10:42.570 --> 00:10:44.210
Machtkonzentrationen.

315
00:10:45.570 --> 00:10:48.250
Auch Staaten nutzen KI, z.B.

316
00:10:48.250 --> 00:10:49.490
zur Überwachung oder

317
00:10:49.490 --> 00:10:51.330
Meinungsbeeinflussung.

318
00:10:51.330 --> 00:10:52.930
Ein bekanntes Beispiel ist das

319
00:10:52.930 --> 00:10:55.250
chinesische Social Scoring System.

320
00:10:56.930 --> 00:10:58.250
Gleichzeitig verändert

321
00:10:58.250 --> 00:10:59.890
KI die Kultur.

322
00:10:59.890 --> 00:11:01.930
Sie kann Kunstwerke erzeugen

323
00:11:01.930 --> 00:11:03.570
oder Musik komponieren.

324
00:11:04.130 --> 00:11:05.690
Wird mit den Funktionen zur

325
00:11:05.690 --> 00:11:07.530
Bildbearbeitung im Smartphone

326
00:11:07.530 --> 00:11:08.130
beispielsweise

327
00:11:08.710 --> 00:11:11.230
jeder zum Künstler oder was ist

328
00:11:11.230 --> 00:11:12.870
dann überhaupt ein Bild?

329
00:11:12.870 --> 00:11:14.230
Dies wirft Fragen nach

330
00:11:14.230 --> 00:11:16.470
Urheberschaft und Kreativität auf.

331
00:11:17.990 --> 00:11:19.390
Doch es stellt sich auch eine

332
00:11:19.390 --> 00:11:22.030
grundsätzliche wer kontrolliert

333
00:11:22.030 --> 00:11:23.630
die Entwicklung und den Einsatz

334
00:11:23.630 --> 00:11:26.310
von KI und wer profitiert davon?

335
00:11:26.310 --> 00:11:28.550
Der Zugang zu modernen KI Systemen

336
00:11:28.550 --> 00:11:30.390
ist sehr ungleich verteilt.

337
00:11:30.390 --> 00:11:32.310
Große Unternehmen verfügen über

338
00:11:32.310 --> 00:11:33.750
die nötige Infrastruktur,

339
00:11:34.470 --> 00:11:36.790
Datenmengen und Kapital, zumeist

340
00:11:36.790 --> 00:11:39.190
ohne vollständige Transparenz.

341
00:11:39.190 --> 00:11:40.430
Ihre Geschäftsmodelle

342
00:11:40.430 --> 00:11:41.630
basieren häufig auf der

343
00:11:41.630 --> 00:11:43.270
Nutzung von Nutzerdaten.

344
00:11:43.270 --> 00:11:44.790
Die automatisch und

345
00:11:44.790 --> 00:11:46.350
vielfach unbewusst zur

346
00:11:46.350 --> 00:11:47.590
Verfügung gestellt werden.

347
00:11:49.110 --> 00:11:50.670
So entstehen ungleiche

348
00:11:50.670 --> 00:11:52.150
Machtverhältnisse.

349
00:11:52.150 --> 00:11:54.030
Während viele KI lediglich

350
00:11:54.030 --> 00:11:55.950
anwenden, entscheiden einige

351
00:11:55.950 --> 00:11:57.750
wenige über deren Gestaltung,

352
00:11:57.750 --> 00:11:59.430
Reichweite und Zielrichtung.

353
00:12:01.200 --> 00:12:02.920
Auch im öffentlichen Sektor stellt

354
00:12:02.920 --> 00:12:05.000
sich die Frage, wie digitale

355
00:12:05.000 --> 00:12:07.360
Souveränität gewahrt werden kann.

356
00:12:07.360 --> 00:12:09.120
Wer bestimmt die Regeln für den

357
00:12:09.120 --> 00:12:11.760
KI Einsatz in Bildung, Verwaltung

358
00:12:11.760 --> 00:12:13.840
oder öffentlichen Räumen?

359
00:12:13.840 --> 00:12:15.640
Wenn Plattformen nicht öffentlich

360
00:12:15.640 --> 00:12:17.600
rechtlich gesteuert sind, können

361
00:12:17.600 --> 00:12:19.760
ökonomische Interessen dominieren.

362
00:12:21.280 --> 00:12:23.440
Deshalb braucht es klare politische

363
00:12:23.440 --> 00:12:25.640
Strategien, demokratische

364
00:12:25.640 --> 00:12:27.700
Kontrolle, Transparenz und

365
00:12:27.700 --> 00:12:29.420
Teilhabe sicherzustellen.

366
00:12:30.380 --> 00:12:32.620
Alltagsbeispiele für KI als

367
00:12:32.620 --> 00:12:35.860
gesellschaftliche KI wirkt oft im

368
00:12:35.860 --> 00:12:38.340
Verborgenen, aber mit spürbaren

369
00:12:38.340 --> 00:12:39.740
Konsequenzen im Alltag.

370
00:12:41.260 --> 00:12:43.340
Streamingdienste analysieren

371
00:12:43.340 --> 00:12:45.380
das bisherige Sehverhalten und

372
00:12:45.380 --> 00:12:47.740
schlagen passende Inhalte vor.

373
00:12:47.740 --> 00:12:49.700
Nachrichten Apps priorisieren

374
00:12:49.700 --> 00:12:50.780
Meldungen mit hoher

375
00:12:50.780 --> 00:12:51.900
Klickwahrscheinlichkeit.

376
00:12:54.160 --> 00:12:55.320
Beim Online shopping

377
00:12:55.320 --> 00:12:56.840
erscheinen personalisierte

378
00:12:56.840 --> 00:12:58.080
Werbung und Preise.

379
00:12:59.600 --> 00:13:01.720
Auch Sprachassistenten wie Alexa

380
00:13:01.720 --> 00:13:04.040
oder Siri geben Empfehlungen, die

381
00:13:04.040 --> 00:13:05.920
Einstellungen beeinflussen können.

382
00:13:06.480 --> 00:13:09.680
Diese Beispiele zeigen KI wirkt

383
00:13:09.680 --> 00:13:10.800
im Hintergrund,

384
00:13:10.800 --> 00:13:12.480
aber mit deutlichen Folgen.

385
00:13:14.080 --> 00:13:15.520
Deshalb sollten wir kritisch

386
00:13:15.520 --> 00:13:16.880
hinterfragen, wer

387
00:13:16.880 --> 00:13:18.960
Algorithmen gestaltet und welche

388
00:13:18.960 --> 00:13:20.320
Annahmen darin stecken.

389
00:13:20.990 --> 00:13:22.590
So übernehmen wir Verantwortung

390
00:13:22.590 --> 00:13:24.190
für einen bewussten Umgang

391
00:13:24.190 --> 00:13:25.790
mit dieser Technologie.

392
00:13:25.790 --> 00:13:27.630
Welche Rolle spielt KI nun

393
00:13:27.630 --> 00:13:29.150
konkret im Bildungssystem?

394
00:13:32.190 --> 00:13:33.750
In diesem Abschnitt geht es

395
00:13:33.750 --> 00:13:35.470
den Einsatz im Bildungsbereich

396
00:13:35.470 --> 00:13:36.750
und in der Verwaltung.

397
00:13:37.790 --> 00:13:40.030
KI Systeme unterstützen schulische

398
00:13:40.030 --> 00:13:42.030
Akteure auf vielfältige Weise.

399
00:13:43.630 --> 00:13:45.350
Lernende profitieren von

400
00:13:45.350 --> 00:13:47.430
Lernprogrammen, die Aufgaben an

401
00:13:47.430 --> 00:13:48.670
den Lernstand anpassen,

402
00:13:49.370 --> 00:13:51.850
sowie von KI gestütztem Feedback.

403
00:13:53.130 --> 00:13:54.770
Lehrkräfte nutzen Tools

404
00:13:54.770 --> 00:13:55.730
beispielsweise zur

405
00:13:55.730 --> 00:13:57.210
Materialerstellung,

406
00:13:57.210 --> 00:13:58.970
Textbearbeitung oder für

407
00:13:58.970 --> 00:14:00.570
Korrekturvorschläge.

408
00:14:01.850 --> 00:14:03.210
In der Verwaltung helfen

409
00:14:03.210 --> 00:14:04.530
KI Anwendungen bei

410
00:14:04.530 --> 00:14:06.010
Textzusammenfassungen,

411
00:14:06.010 --> 00:14:07.490
Datenanalysen oder

412
00:14:07.490 --> 00:14:09.450
zur Personalplanung.

413
00:14:09.450 --> 00:14:10.970
Auch Sprachtools und

414
00:14:10.970 --> 00:14:12.770
barrierefreie Anwendungen kommen

415
00:14:12.770 --> 00:14:14.010
vermehrt zum Einsatz.

416
00:14:15.300 --> 00:14:16.980
Damit KI sinnvoll genutzt

417
00:14:16.980 --> 00:14:18.580
werden kann, braucht es eine

418
00:14:18.580 --> 00:14:20.580
bewusste didaktische Planung.

419
00:14:22.180 --> 00:14:24.700
Vor dem Einsatz sollten klare Ziele

420
00:14:24.700 --> 00:14:27.060
definiert werden, beispielsweise

421
00:14:27.060 --> 00:14:28.980
zur Individualisierung,

422
00:14:28.980 --> 00:14:30.660
Sprachförderung,

423
00:14:30.660 --> 00:14:32.820
Inklusion oder Entlastung.

424
00:14:34.340 --> 00:14:36.460
Die Auswahl geeigneter Anwendungen

425
00:14:36.460 --> 00:14:38.340
sollte pädagogisch begründet,

426
00:14:38.340 --> 00:14:40.020
lernpsychologisch fundiert

427
00:14:40.590 --> 00:14:42.350
und technisch kompatibel sein.

428
00:14:43.950 --> 00:14:46.470
KI ersetzt keine pädagogischen

429
00:14:46.470 --> 00:14:48.510
Konzepte, sie ergänzt sie.

430
00:14:50.670 --> 00:14:52.030
Die Rolle der Lehrkraft

431
00:14:52.030 --> 00:14:54.030
verändert sich weg von der

432
00:14:54.030 --> 00:14:55.390
reinen Wissensvermittlung

433
00:14:55.390 --> 00:14:57.630
hin zur Lernbegleitung.

434
00:14:57.630 --> 00:14:59.790
KI kann Aufgaben übernehmen,

435
00:14:59.790 --> 00:15:01.150
ersetzt aber nicht das

436
00:15:01.150 --> 00:15:03.310
pädagogische Urteil oder die

437
00:15:03.310 --> 00:15:04.670
Gestaltung von Beziehungen.

438
00:15:06.520 --> 00:15:08.320
Auch in fachlichen, didaktischen

439
00:15:08.320 --> 00:15:10.040
und medienethischen Bereichen

440
00:15:10.040 --> 00:15:11.760
benötigen Lehrkräfte neue

441
00:15:11.760 --> 00:15:13.800
medienethische Kompetenzen.

442
00:15:14.600 --> 00:15:16.320
Eine offene Fehlerkultur ist

443
00:15:16.320 --> 00:15:18.600
entscheidend, Erfahrungen mit KI

444
00:15:18.600 --> 00:15:20.120
gemeinsam zu reflektieren.

445
00:15:21.400 --> 00:15:22.920
Auch Schülerinnen und Schüler

446
00:15:22.920 --> 00:15:24.760
benötigen neue Kompetenzen.

447
00:15:26.040 --> 00:15:28.080
Sie sollen KI als Werkzeug

448
00:15:28.080 --> 00:15:29.720
nutzen, nicht als Ersatz.

449
00:15:30.360 --> 00:15:32.040
Systeme wie ChatGPT

450
00:15:32.610 --> 00:15:34.450
können Lernprozesse unterstützen,

451
00:15:34.450 --> 00:15:35.650
dürfen aber nicht zu

452
00:15:35.650 --> 00:15:37.330
passivem Konsum führen.

453
00:15:38.690 --> 00:15:41.330
Entscheidend Ergebnisse bewerten,

454
00:15:41.330 --> 00:15:42.850
Mechanismen verstehen,

455
00:15:42.850 --> 00:15:46.730
kritisch hinterfragen, Medien und

456
00:15:46.730 --> 00:15:49.050
Datenkompetenz Selbststeuerung

457
00:15:49.050 --> 00:15:50.850
und Problemlösungsfähigkeit

458
00:15:50.850 --> 00:15:52.770
sind zentrale Voraussetzungen.

459
00:15:54.210 --> 00:15:56.050
Die Perspektive der Lernenden

460
00:15:56.050 --> 00:15:58.170
sollte aktiv in Bildungsprozesse

461
00:15:58.170 --> 00:15:58.930
einbezogen werden.

462
00:15:59.810 --> 00:16:01.010
Nur so gelingt es,

463
00:16:01.010 --> 00:16:03.690
Chancengerechtigkeit und digitale

464
00:16:03.690 --> 00:16:05.330
Souveränität zu stärken.

465
00:16:06.770 --> 00:16:08.450
Auch die Bewertungspraxis

466
00:16:08.450 --> 00:16:09.890
muss sich weiterentwickeln.

467
00:16:11.410 --> 00:16:13.730
Schulen müssen neue Prüfungsformate

468
00:16:13.730 --> 00:16:15.410
gestalten, die kreative

469
00:16:15.410 --> 00:16:17.730
und reflexive Leistungen abbilden,

470
00:16:17.730 --> 00:16:20.250
unabhängig davon, ob KI im

471
00:16:20.250 --> 00:16:21.810
Prozess eingesetzt wurde.

472
00:16:23.410 --> 00:16:25.330
Dazu braucht es klare Kriterien,

473
00:16:25.880 --> 00:16:27.280
die zwischen eigener Leistung

474
00:16:27.280 --> 00:16:29.480
und KI Assistenz unterscheiden,

475
00:16:29.480 --> 00:16:31.720
und transparent kommunizieren,

476
00:16:31.720 --> 00:16:33.400
welche Tools erlaubt sind.

477
00:16:35.080 --> 00:16:36.920
Ziel ist es, junge Menschen zu

478
00:16:36.920 --> 00:16:39.320
mündigen, digital souveränen

479
00:16:39.320 --> 00:16:40.920
Persönlichkeiten zu befähigen.

480
00:16:43.320 --> 00:16:45.480
Gleichzeitig wirft der Wandel neue

481
00:16:45.480 --> 00:16:47.240
Fragen im Klassenzimmer auf.

482
00:16:48.680 --> 00:16:51.120
Was passiert, wenn algorithmisches

483
00:16:51.120 --> 00:16:52.160
Feedback wichtiger

484
00:16:52.160 --> 00:16:53.400
wird als das menschliche?

485
00:16:55.170 --> 00:16:56.490
Wenn Bewertungen nicht mehr

486
00:16:56.490 --> 00:16:57.730
nachvollziehbar sind?

487
00:16:59.170 --> 00:17:01.090
Wenn verzerrte Trainingsdaten

488
00:17:01.090 --> 00:17:02.690
Ungleichheiten verstärken?

489
00:17:03.650 --> 00:17:06.130
Deshalb Entscheidungen müssen

490
00:17:06.130 --> 00:17:07.849
nachvollziehbar bleiben und der

491
00:17:07.849 --> 00:17:09.329
Mensch bleibt verantwortlich.

492
00:17:09.890 --> 00:17:11.690
Schulen tragen die Verantwortung,

493
00:17:11.690 --> 00:17:13.130
sicherzustellen, dass

494
00:17:13.130 --> 00:17:15.490
KI Angebote allen Lernenden

495
00:17:15.490 --> 00:17:17.170
zugänglich sind und keine

496
00:17:17.170 --> 00:17:18.770
neuen Barrieren entstehen.

497
00:17:20.540 --> 00:17:21.980
Diese Entwicklungen erfordern

498
00:17:21.980 --> 00:17:23.819
eine bewusste Auseinandersetzung

499
00:17:23.819 --> 00:17:25.660
mit pädagogischer Verantwortung,

500
00:17:26.220 --> 00:17:28.140
professioneller Identität,

501
00:17:28.140 --> 00:17:29.860
Machtverhältnissen und

502
00:17:29.860 --> 00:17:31.500
digitaler Souveränität.

503
00:17:32.220 --> 00:17:33.540
Nur wenn Lehrkräfte

504
00:17:33.540 --> 00:17:35.219
Gestaltungsspielräume aktiv

505
00:17:35.219 --> 00:17:37.700
wahrnehmen, kann KI sinnvoll in

506
00:17:37.700 --> 00:17:39.980
ein humanes, wertebasiertes

507
00:17:39.980 --> 00:17:42.060
Bildungsideal eingebettet werden.

508
00:17:44.380 --> 00:17:46.060
Besonders relevant sind die

509
00:17:46.060 --> 00:17:50.160
folgenden ethischen Verzerrungen

510
00:17:50.160 --> 00:17:53.280
in KI Systemen sogenannte Bias

511
00:17:53.280 --> 00:17:54.960
müssen erkannt und aktiv

512
00:17:54.960 --> 00:17:56.720
korrigiert werden, damit keine

513
00:17:56.720 --> 00:17:58.320
Gruppen benachteiligt werden.

514
00:17:59.840 --> 00:18:01.840
Beim Umgang mit sensiblen Daten

515
00:18:01.840 --> 00:18:04.320
ist Datenschutz essentiell.

516
00:18:04.320 --> 00:18:05.840
Es braucht klare Regeln,

517
00:18:05.840 --> 00:18:07.480
wie Daten gespeichert und

518
00:18:07.480 --> 00:18:08.960
verarbeitet werden dürfen.

519
00:18:10.480 --> 00:18:12.080
Entscheidungen, die mit Hilfe

520
00:18:12.080 --> 00:18:13.600
von KI getroffen werden

521
00:18:13.600 --> 00:18:14.960
müssen, müssen transparent

522
00:18:14.960 --> 00:18:16.480
und nachvollziehbar sein.

523
00:18:17.920 --> 00:18:19.640
Menschen müssen die Verantwortung

524
00:18:19.640 --> 00:18:21.000
für den KI Einsatz

525
00:18:21.000 --> 00:18:22.680
übernehmen und dürfen diese

526
00:18:22.680 --> 00:18:24.800
nicht auf Systeme abwälzen.

527
00:18:24.800 --> 00:18:26.240
Die Entscheidungsbefugnis

528
00:18:26.240 --> 00:18:28.000
in Bildung und Verwaltung

529
00:18:28.000 --> 00:18:29.240
muss grundsätzlich

530
00:18:29.240 --> 00:18:30.640
beim Menschen liegen.

531
00:18:32.080 --> 00:18:34.280
KI darf außerdem nicht zu einem

532
00:18:34.280 --> 00:18:36.160
Instrument des Personalabbaus

533
00:18:36.160 --> 00:18:37.520
werden, sondern sollte

534
00:18:37.520 --> 00:18:39.360
Mitarbeitende sinnvoll entlasten.

535
00:18:41.180 --> 00:18:42.660
Schließlich müssen Schulen

536
00:18:42.660 --> 00:18:45.420
definieren, wie mit KI generierten

537
00:18:45.420 --> 00:18:47.420
Leistungen umgegangen wird,

538
00:18:47.420 --> 00:18:48.660
die Integrität von

539
00:18:48.660 --> 00:18:50.860
Leistungsnachweisen zu wahren.

540
00:18:52.220 --> 00:18:54.540
Fallbeispiele aus dem Alltag

541
00:18:56.140 --> 00:18:58.540
eine Lehrkraft nutzt ChatGPT

542
00:18:58.540 --> 00:19:00.060
zur Unterrichtsplanung,

543
00:19:00.060 --> 00:19:02.220
prüft aber kritisch die Inhalte.

544
00:19:03.660 --> 00:19:05.660
Ein Schulamtsmitarbeiter lässt sich

545
00:19:05.660 --> 00:19:07.660
Texte von einer KI zusammenfassen

546
00:19:08.200 --> 00:19:09.160
und achtet auf Datenschutz.

547
00:19:11.160 --> 00:19:12.960
Eine Behörde verzichtet bewusst

548
00:19:12.960 --> 00:19:15.400
auf KI bei der Bewerberauswahl,

549
00:19:15.400 --> 00:19:17.080
Diskriminierung zu vermeiden.

550
00:19:18.600 --> 00:19:20.200
Eine Lehrkraft spricht mit

551
00:19:20.200 --> 00:19:21.920
einem Schüler über KI Nutzung

552
00:19:21.920 --> 00:19:23.680
bei einer Hausaufgabe, statt

553
00:19:23.680 --> 00:19:25.320
sofort zu sanktionieren.

554
00:19:26.280 --> 00:19:28.360
Diese Fälle der Umgang

555
00:19:28.360 --> 00:19:29.520
mit KI erfordert

556
00:19:29.520 --> 00:19:31.960
Augenmaß, Ethikbewusstsein

557
00:19:31.960 --> 00:19:33.640
und klare Leitlinien.

558
00:19:35.390 --> 00:19:37.270
Ziel sollte sein, technologische

559
00:19:37.270 --> 00:19:38.350
Innovation mit

560
00:19:38.350 --> 00:19:40.030
pädagogischer Verantwortung

561
00:19:40.030 --> 00:19:41.270
und gesellschaftlicher

562
00:19:41.270 --> 00:19:42.750
Fairness zu verbinden.

563
00:19:43.950 --> 00:19:45.470
Nach dem Blick auf Gegenwart

564
00:19:45.470 --> 00:19:47.590
und Praxisbeispiele richten

565
00:19:47.590 --> 00:19:49.870
wir den Fokus nun nach vorn.

566
00:19:49.870 --> 00:19:51.350
Wie können wir KI so

567
00:19:51.350 --> 00:19:53.070
gestalten, dass sie ethisch

568
00:19:53.070 --> 00:19:54.590
verantwortungsvoll ist.

569
00:19:54.590 --> 00:19:56.950
Und welche Zukunftsperspektiven

570
00:19:56.950 --> 00:19:57.870
zeichnen sich ab?

571
00:20:00.040 --> 00:20:02.600
Der EU AI Act ist die erste

572
00:20:02.600 --> 00:20:05.240
umfassende KI Verordnung weltweit

573
00:20:05.240 --> 00:20:07.480
und unterscheidet KI Systeme

574
00:20:07.480 --> 00:20:09.560
nach ihrem Risikopotenzial.

575
00:20:10.120 --> 00:20:12.360
Anwendungen mit unvertretbarem

576
00:20:12.360 --> 00:20:14.440
Risiko Social Scoring

577
00:20:14.440 --> 00:20:16.440
beispielsweise sind verboten.

578
00:20:17.800 --> 00:20:20.280
Hochriskante Systeme unterliegen

579
00:20:20.280 --> 00:20:21.800
strengen Auflagen wie

580
00:20:21.800 --> 00:20:24.040
Transparenz, Dokumentation

581
00:20:24.040 --> 00:20:25.560
und menschlicher Aufsicht.

582
00:20:27.310 --> 00:20:29.470
Internationale Leitlinien wie die

583
00:20:29.470 --> 00:20:32.270
UNESCO Empfehlung von 2021

584
00:20:32.270 --> 00:20:34.470
fordern, dass KI gerecht,

585
00:20:34.470 --> 00:20:35.670
transparent und

586
00:20:35.670 --> 00:20:37.870
gemeinwohlorientiert gestaltet

587
00:20:37.870 --> 00:20:38.190
wird.

588
00:20:39.630 --> 00:20:40.950
Für Schulen und Behörden

589
00:20:40.950 --> 00:20:43.310
gibt es zusätzlich Handreichungen,

590
00:20:43.310 --> 00:20:43.990
etwa von der

591
00:20:43.990 --> 00:20:45.670
Kultusministerkonferenz

592
00:20:45.670 --> 00:20:46.750
und der europäischen

593
00:20:46.750 --> 00:20:48.670
Kommission, die eine kritische,

594
00:20:48.670 --> 00:20:50.110
chancengerechte KI

595
00:20:50.110 --> 00:20:50.990
Nutzung empfiehlt.

596
00:20:52.600 --> 00:20:54.080
Die genannten Leitlinien und

597
00:20:54.080 --> 00:20:56.040
Verordnungen setzen wichtige

598
00:20:56.040 --> 00:20:58.840
ethische Maßstäbe wie Transparenz,

599
00:20:58.840 --> 00:21:00.200
Fairness oder Datenschutz.

600
00:21:01.240 --> 00:21:03.240
Doch in der praktischen Umsetzung

601
00:21:03.240 --> 00:21:05.160
bleiben viele Fragen offen.

602
00:21:06.520 --> 00:21:08.520
Wie wird überprüft, ob ein KI

603
00:21:08.520 --> 00:21:10.600
System tatsächlich fair ist?

604
00:21:12.040 --> 00:21:13.360
Wer entscheidet, welche

605
00:21:13.360 --> 00:21:14.840
Verzerrungen akzeptabel

606
00:21:14.840 --> 00:21:16.120
sind und welche nicht?

607
00:21:17.810 --> 00:21:19.250
Und wie lässt sich Transparenz

608
00:21:19.250 --> 00:21:20.330
herstellen, wenn

609
00:21:20.330 --> 00:21:21.690
selbst Entwicklerinnen und

610
00:21:21.690 --> 00:21:23.250
Entwickler komplexer Modelle

611
00:21:23.250 --> 00:21:24.050
ihre genauen

612
00:21:24.050 --> 00:21:25.570
Entscheidungsprozesse nicht mehr

613
00:21:25.570 --> 00:21:27.050
vollständig erklären und

614
00:21:27.050 --> 00:21:28.290
nachvollziehen können?

615
00:21:29.810 --> 00:21:31.130
Auch Zielkonflikte

616
00:21:31.130 --> 00:21:32.450
sind kaum vermeidbar.

617
00:21:33.810 --> 00:21:35.810
Eine datensparsame KI kann

618
00:21:35.810 --> 00:21:38.210
weniger personalisiert arbeiten.

619
00:21:38.210 --> 00:21:40.290
Eine hochpersonalisierte KI

620
00:21:40.290 --> 00:21:42.050
dagegen stellt den Datenschutz

621
00:21:42.050 --> 00:21:43.170
stärker in Frage.

622
00:21:44.930 --> 00:21:46.810
Eine transparente KI verlangt

623
00:21:46.810 --> 00:21:48.530
einfache Erklärbarkeit.

624
00:21:48.530 --> 00:21:49.770
Doch oft sind es die

625
00:21:49.770 --> 00:21:51.770
leistungsstärksten Systeme, die

626
00:21:51.770 --> 00:21:53.810
besonders intransparent agieren.

627
00:21:55.250 --> 00:21:56.890
Ethische Prinzipien sind

628
00:21:56.890 --> 00:21:58.370
daher keine Checkliste,

629
00:21:58.370 --> 00:22:00.290
die einmal abgehakt wird.

630
00:22:00.290 --> 00:22:01.450
Sie müssen immer wieder

631
00:22:01.450 --> 00:22:03.730
kontextbezogen ausgehandelt und

632
00:22:03.730 --> 00:22:05.930
mit konkreten Handlungsspielräumen

633
00:22:05.930 --> 00:22:06.690
verbunden werden.

634
00:22:07.410 --> 00:22:09.620
Das verlangt Zeit, Ressourcen

635
00:22:09.620 --> 00:22:11.380
und Beteiligung und kann nicht

636
00:22:11.380 --> 00:22:12.780
allein durch Technik

637
00:22:12.780 --> 00:22:14.780
oder Gesetzgebung ersetzt werden.

638
00:22:17.020 --> 00:22:19.060
In der Praxis sollte diese

639
00:22:19.060 --> 00:22:20.900
Aushandlung auf verschiedenen

640
00:22:20.900 --> 00:22:22.940
Ebenen und schrittweise geschehen.

641
00:22:24.220 --> 00:22:25.940
Die Politik legt den rechtlichen

642
00:22:25.940 --> 00:22:27.620
Rahmen fest und fördert

643
00:22:27.620 --> 00:22:29.100
Forschung und Ausstattung.

644
00:22:30.460 --> 00:22:32.340
Schulträger prüfen gemeinsam

645
00:22:32.340 --> 00:22:33.180
mit Schule

646
00:22:33.180 --> 00:22:35.180
den geplanten Einsatz von Tools.

647
00:22:36.880 --> 00:22:38.600
In der Bildungsverwaltung werden

648
00:22:38.600 --> 00:22:40.480
Schulungskonzepte entwickelt.

649
00:22:41.920 --> 00:22:43.720
Schulleitungen und Kollegien

650
00:22:43.720 --> 00:22:45.040
gestalten Regeln für den

651
00:22:45.040 --> 00:22:46.960
KI Einsatz im Alltag

652
00:22:46.960 --> 00:22:48.640
und fördern den Austausch.

653
00:22:50.000 --> 00:22:51.160
Lehrkräfte und

654
00:22:51.160 --> 00:22:52.440
Verwaltungsangestellte

655
00:22:52.440 --> 00:22:54.400
reflektieren ihre Praxis und

656
00:22:54.400 --> 00:22:55.680
achten auf Datenschutz

657
00:22:55.680 --> 00:22:56.800
und Transparenz.

658
00:22:58.320 --> 00:23:00.040
Auch Schülerinnen, Schüler und

659
00:23:00.040 --> 00:23:02.550
Eltern tragen Verantwortung, z.B.

660
00:23:02.550 --> 00:23:03.870
durch verantwortungsvollen

661
00:23:03.870 --> 00:23:05.430
Umgang mit KI und

662
00:23:05.430 --> 00:23:07.190
konstruktive Rückmeldung.

663
00:23:09.110 --> 00:23:11.310
Gute KI Governance braucht

664
00:23:11.310 --> 00:23:12.390
Zusammenarbeit,

665
00:23:12.390 --> 00:23:14.830
klare Zuständigkeiten und eine

666
00:23:14.830 --> 00:23:17.270
offene Kommunikationskultur.

667
00:23:17.270 --> 00:23:19.070
Der Begriff bezeichnet die

668
00:23:19.070 --> 00:23:21.030
Gesamtheit aller politischen,

669
00:23:21.030 --> 00:23:22.270
organisatorischen

670
00:23:22.270 --> 00:23:24.070
und ethischen Maßnahmen,

671
00:23:24.070 --> 00:23:25.550
mit denen der Einsatz von

672
00:23:25.550 --> 00:23:27.600
KI Systemen gesteuert,

673
00:23:27.600 --> 00:23:29.600
überwacht und verantwortungsvoll

674
00:23:29.600 --> 00:23:30.480
gestaltet wird.

675
00:23:31.040 --> 00:23:32.960
Ziel ist es, gesellschaftliche

676
00:23:32.960 --> 00:23:34.560
Werte wie Transparenz,

677
00:23:34.560 --> 00:23:36.680
Fairness und Datenschutz in den

678
00:23:36.680 --> 00:23:38.520
Entwicklungs und Einsatzprozess

679
00:23:38.520 --> 00:23:40.400
von KI zu integrieren.

680
00:23:41.840 --> 00:23:44.000
Ethisch gestaltete KI kann

681
00:23:44.000 --> 00:23:45.120
vielfältige Vorteile

682
00:23:46.960 --> 00:23:48.880
transparente Entscheidungen,

683
00:23:48.880 --> 00:23:51.280
individuelle Lernunterstützung,

684
00:23:51.280 --> 00:23:51.920
Datenschutz

685
00:23:51.920 --> 00:23:53.440
durch datensparsame Technik

686
00:23:53.970 --> 00:23:55.010
und die Förderung von

687
00:23:55.010 --> 00:23:57.090
Kreativität und Teilhabe.

688
00:23:58.450 --> 00:24:00.530
Doch diese Potenziale entfalten

689
00:24:00.530 --> 00:24:02.610
sich nur, wenn sie bewusst

690
00:24:02.610 --> 00:24:04.690
gerecht und verantwortungsvoll

691
00:24:04.690 --> 00:24:05.650
gestaltet werden.

692
00:24:07.650 --> 00:24:08.970
Was heißt das konkret

693
00:24:08.970 --> 00:24:10.850
für unsere Praxis?

694
00:24:10.850 --> 00:24:12.370
Zum Abschluss möchten wir ihnen

695
00:24:12.370 --> 00:24:14.650
einige Fragen mitgeben, die dabei

696
00:24:14.650 --> 00:24:16.650
helfen können, den Einsatz von

697
00:24:16.650 --> 00:24:18.770
KI in Schule oder Verwaltung

698
00:24:18.770 --> 00:24:20.610
kritisch und bewusst zu gestalten.

699
00:24:21.270 --> 00:24:22.910
Diese Impulse eignen sich auch

700
00:24:22.910 --> 00:24:25.030
für Teamrunden, Fortbildungen

701
00:24:25.030 --> 00:24:26.790
oder Leitbildprozesse.

702
00:24:27.990 --> 00:24:29.830
Wo und wie wollen wir KI

703
00:24:29.830 --> 00:24:31.830
einsetzen und wo bewusst nicht?

704
00:24:33.190 --> 00:24:34.710
Welche Werte leiten unser

705
00:24:34.710 --> 00:24:36.310
Handeln im Umgang mit KI?

706
00:24:37.750 --> 00:24:39.270
Wie erklären wir Entscheidungen

707
00:24:39.270 --> 00:24:40.750
rund KI gegenüber

708
00:24:40.750 --> 00:24:42.310
Kolleginnen und Kollegen,

709
00:24:42.310 --> 00:24:45.510
Lernenden oder externen wie z.B.

710
00:24:45.510 --> 00:24:46.870
eltern oder Kunden?

711
00:24:48.650 --> 00:24:50.610
Ethisch verantwortungsvoller KI

712
00:24:50.610 --> 00:24:52.570
Einsatz gelingt nicht allein durch

713
00:24:52.570 --> 00:24:54.810
Gesetze oder technische Lösungen.

714
00:24:54.810 --> 00:24:56.530
Er entsteht dort, wo Menschen

715
00:24:56.530 --> 00:24:57.770
aktiv mitdenken,

716
00:24:57.770 --> 00:24:59.690
mitreden und mitentscheiden.

717
00:25:01.130 --> 00:25:03.450
In Schulen und Verwaltungen heißt

718
00:25:03.450 --> 00:25:05.370
regeln gemeinsam entwickeln,

719
00:25:05.370 --> 00:25:07.450
neue Werkzeuge reflektieren,

720
00:25:07.450 --> 00:25:09.170
erproben und offen

721
00:25:09.170 --> 00:25:10.970
über Erfahrungen sprechen,

722
00:25:10.970 --> 00:25:12.570
auch über Unsicherheiten.

723
00:25:14.540 --> 00:25:15.780
Die Reflexionsfragen,

724
00:25:15.780 --> 00:25:16.740
die wir vorgestellt

725
00:25:16.740 --> 00:25:18.700
haben, sind ein Anfang.

726
00:25:18.700 --> 00:25:20.300
Entscheidend ist, dass sie

727
00:25:20.300 --> 00:25:21.660
nicht im Theoretischen

728
00:25:21.660 --> 00:25:23.500
bleiben, sondern im Alltag.

729
00:25:24.380 --> 00:25:25.740
In Fortbildungen,

730
00:25:25.740 --> 00:25:27.420
in Dienstbesprechungen,

731
00:25:27.420 --> 00:25:29.340
in Elterngesprächen und unter

732
00:25:29.340 --> 00:25:31.340
Kolleginnen und Kollegen.

733
00:25:31.340 --> 00:25:33.460
Wenn wir KI nicht als fertige

734
00:25:33.460 --> 00:25:35.940
Lösung, sondern als verhandelbares

735
00:25:35.940 --> 00:25:38.060
Werkzeug verstehen, können wir sie

736
00:25:38.060 --> 00:25:39.660
an unseren Werten ausrichten.

737
00:25:41.510 --> 00:25:42.790
Dabei geht es weniger

738
00:25:42.790 --> 00:25:45.270
das perfekte System als eine

739
00:25:46.150 --> 00:25:49.190
offen, kritisch, lernbereit.

740
00:25:49.190 --> 00:25:51.350
So entsteht ein Arbeitsumfeld,

741
00:25:51.350 --> 00:25:53.790
in dem technische Innovation und

742
00:25:53.790 --> 00:25:55.430
gesellschaftliche Verantwortung

743
00:25:55.430 --> 00:25:57.030
gemeinsam gedacht werden.

744
00:25:58.070 --> 00:25:59.470
Wir fassen die zentralen

745
00:25:59.470 --> 00:26:01.110
Erkenntnisse dieses Videos

746
00:26:05.940 --> 00:26:08.020
KI ist Teil unserer Gegenwart,

747
00:26:08.020 --> 00:26:10.020
auch in Bildung und Verwaltung.

748
00:26:10.020 --> 00:26:12.420
Wegschauen ist keine Lösung.

749
00:26:12.420 --> 00:26:14.380
Stattdessen sollten wir verstehen,

750
00:26:14.380 --> 00:26:17.140
reflektieren und mitgestalten.

751
00:26:17.140 --> 00:26:18.700
Wer informiert bleibt und

752
00:26:18.700 --> 00:26:20.500
sich aktiv einbringt, kann

753
00:26:20.500 --> 00:26:21.980
den Einsatz von KI

754
00:26:21.980 --> 00:26:23.780
verantwortungsvoll mitprägen.

755
00:26:25.380 --> 00:26:27.620
Der Mensch bleibt im Mittelpunkt.

756
00:26:27.620 --> 00:26:29.300
KI kann unterstützen,

757
00:26:29.300 --> 00:26:30.740
aber nicht ersetzen.

758
00:26:31.470 --> 00:26:32.230
Lehrkräfte und

759
00:26:32.230 --> 00:26:34.310
Verwaltungsmitarbeitende tragen

760
00:26:34.310 --> 00:26:36.390
Verantwortung und sollten KI

761
00:26:36.390 --> 00:26:38.510
Ergebnisse kritisch prüfen.

762
00:26:38.510 --> 00:26:40.830
Das Prinzip die Entscheidung

763
00:26:40.830 --> 00:26:41.870
trifft der Mensch.

764
00:26:43.390 --> 00:26:45.030
KI Kompetenz ist eine

765
00:26:45.030 --> 00:26:46.510
Schlüsselqualifikation.

766
00:26:47.070 --> 00:26:49.150
Fortbildungen, kollegialer

767
00:26:49.150 --> 00:26:51.270
Austausch und eigene Erprobung

768
00:26:51.270 --> 00:26:53.790
helfen, den Umgang mit KI sicher

769
00:26:53.790 --> 00:26:56.110
und reflektiert zu gestalten.

770
00:26:56.110 --> 00:26:58.300
Nur durch Erfahrung entsteht

771
00:26:58.300 --> 00:26:59.900
ein realistisches Bild der

772
00:26:59.900 --> 00:27:01.620
Möglichkeiten und Grenzen.

773
00:27:03.140 --> 00:27:04.940
Institutionelle Leitlinien

774
00:27:04.940 --> 00:27:05.860
geben Sicherheit.

775
00:27:06.420 --> 00:27:08.220
Schulen und Behörden sollten

776
00:27:08.220 --> 00:27:10.460
gemeinsam Spielregeln für den KI

777
00:27:10.460 --> 00:27:12.660
Einsatz definieren, angepasst

778
00:27:12.660 --> 00:27:14.260
an ihre jeweilige Situation.

779
00:27:14.820 --> 00:27:16.500
So entsteht Orientierung

780
00:27:16.500 --> 00:27:18.500
für alle Beteiligten.

781
00:27:18.500 --> 00:27:20.220
Fü bleiben sie

782
00:27:20.220 --> 00:27:22.020
kritisch optimistisch.

783
00:27:22.020 --> 00:27:23.700
Weder blinder Technikglaube

784
00:27:23.700 --> 00:27:24.840
noch pauschale

785
00:27:24.840 --> 00:27:26.800
Ablehnung helfen weiter.

786
00:27:26.800 --> 00:27:28.560
Wer offen, aber prüfend an

787
00:27:28.560 --> 00:27:30.320
das Thema herangeht, schafft

788
00:27:30.320 --> 00:27:31.760
eine gute Grundlage für

789
00:27:31.760 --> 00:27:33.760
lernende Organisationen mit

790
00:27:33.760 --> 00:27:35.680
positiver Fehlerkultur.

791
00:27:39.040 --> 00:27:41.360
Informieren, ausprobieren,

792
00:27:41.360 --> 00:27:44.080
reflektieren, regulieren.

793
00:27:44.080 --> 00:27:45.600
Diese vier Schritte helfen,

794
00:27:45.600 --> 00:27:47.840
den Wandel aktiv zu gestalten.

795
00:27:48.800 --> 00:27:50.160
Nutzen Sie auch bestehende

796
00:27:50.160 --> 00:27:52.080
Ressourcen wie Impulspapiere der

797
00:27:52.080 --> 00:27:54.920
KMK, UNESCO Leitfäden oder

798
00:27:54.920 --> 00:27:55.760
Angebote der

799
00:27:55.760 --> 00:27:57.840
Datenschutzbeauftragten und des

800
00:27:57.840 --> 00:27:58.800
NLQ.

801
00:27:58.800 --> 00:28:01.120
Ethik ist kein fertiges Regelwerk,

802
00:28:01.120 --> 00:28:02.560
sondern ein gemeinsamer

803
00:28:02.560 --> 00:28:04.240
Aushandlungsprozess.

804
00:28:04.240 --> 00:28:06.320
Denn nur im gemeinsamen Dialog

805
00:28:06.320 --> 00:28:08.680
entsteht eine KI Kultur, die

806
00:28:08.680 --> 00:28:10.360
unseren Werten gerecht wird.

807
00:28:10.360 --> 00:28:12.880
Und den Menschen im Zentrum behält.

808
00:28:14.480 --> 00:28:16.000
Doch wie geht es weiter?

809
00:28:16.560 --> 00:28:18.080
Ein Blick in die Zukunft

810
00:28:18.730 --> 00:28:20.090
was könnte uns in den nächsten

811
00:28:20.090 --> 00:28:22.130
Jahren und Jahrzehnten in Bezug

812
00:28:22.130 --> 00:28:24.370
auf KI in Bildung, Verwaltung

813
00:28:24.370 --> 00:28:26.090
und Gesellschaft erwarten?

814
00:28:28.890 --> 00:28:30.130
KI wird weiter an

815
00:28:30.130 --> 00:28:31.690
Leistungsfähigkeit gewinnen,

816
00:28:31.690 --> 00:28:33.050
insbesondere im Bereich

817
00:28:33.050 --> 00:28:34.410
generativer Modelle.

818
00:28:34.970 --> 00:28:36.450
Damit werden Deepfakes

819
00:28:36.450 --> 00:28:38.210
realistischer, Übersetzungen

820
00:28:38.210 --> 00:28:40.170
schneller und interaktive

821
00:28:40.170 --> 00:28:41.930
Anwendungen breiter nutzbar.

822
00:28:42.570 --> 00:28:46.580
Die Manipulation erkennen lernen.

823
00:28:47.220 --> 00:28:48.940
Chancen bestehen im Abbau

824
00:28:48.940 --> 00:28:50.860
von Sprachbarrieren und in

825
00:28:50.860 --> 00:28:52.380
der besseren Planbarkeit

826
00:28:52.380 --> 00:28:54.740
politischer Maßnahmen durch KI

827
00:28:54.740 --> 00:28:56.500
gestützte Simulationen.

828
00:28:57.060 --> 00:28:58.420
Auch rechtliche Fragen

829
00:28:58.420 --> 00:29:00.140
werden drängender, etwa ob

830
00:29:00.140 --> 00:29:01.740
autonome Systeme rechtlich

831
00:29:01.740 --> 00:29:03.460
erfasst werden müssen.

832
00:29:03.460 --> 00:29:05.540
Die Werte und Rechtsordnung wird

833
00:29:05.540 --> 00:29:07.380
sich mitentwickeln müssen.

834
00:29:07.380 --> 00:29:09.180
Eine hybride Lernumgebung

835
00:29:09.180 --> 00:29:10.740
aus Lehrkraft und KI

836
00:29:10.740 --> 00:29:11.780
wird wahrscheinlicher.

837
00:29:12.670 --> 00:29:14.510
KI könnte Routineaufgaben

838
00:29:14.510 --> 00:29:16.030
übernehmen, individuelle

839
00:29:16.030 --> 00:29:17.830
Lernpfade gestalten und

840
00:29:17.830 --> 00:29:20.030
inklusive Bildung stärken.

841
00:29:20.030 --> 00:29:23.070
Die Rolle der Lehrkraft bleibt als

842
00:29:23.070 --> 00:29:25.470
Lernbegleitung Vertrauensperson

843
00:29:25.470 --> 00:29:26.990
und ethische Instanz.

844
00:29:27.550 --> 00:29:29.710
Gleichzeitig wird KI Kompetenz

845
00:29:29.710 --> 00:29:31.630
Teil der schulischen Bildung.

846
00:29:31.630 --> 00:29:34.270
AI Literacy dürfte fest in den

847
00:29:34.270 --> 00:29:36.190
Curricula verankert werden.

848
00:29:36.190 --> 00:29:38.190
KI basierte Prüfungsformate,

849
00:29:38.700 --> 00:29:40.700
Simulationsszenarien und

850
00:29:40.700 --> 00:29:42.220
unterstützende Tools für

851
00:29:42.220 --> 00:29:44.180
mehrsprachige Klassen könnten

852
00:29:44.180 --> 00:29:45.740
den Schulalltag verändern.

853
00:29:46.380 --> 00:29:48.340
In der Verwaltung könnten KI

854
00:29:48.340 --> 00:29:49.660
Systeme dabei helfen,

855
00:29:49.660 --> 00:29:52.060
Raum und Einsatzpläne effizienter

856
00:29:52.060 --> 00:29:54.459
zu koordinieren oder Prognosen

857
00:29:54.459 --> 00:29:55.940
über Schülerzahlen und

858
00:29:55.940 --> 00:29:57.660
Personalbedarf zu erstellen.

859
00:29:58.220 --> 00:30:00.100
Auf regulatorischer Ebene

860
00:30:00.100 --> 00:30:01.780
könnten sich internationale

861
00:30:01.780 --> 00:30:03.500
Standards etablieren.

862
00:30:03.500 --> 00:30:05.860
Berufsfelder wie Algorithmusprüfer

863
00:30:05.860 --> 00:30:06.700
könnten entstehen.

864
00:30:07.500 --> 00:30:09.220
KI wird voraussichtlich auch

865
00:30:09.220 --> 00:30:10.780
in sensiblen Bereichen wie

866
00:30:10.780 --> 00:30:12.980
Medizin oder Justiz stärker

867
00:30:12.980 --> 00:30:15.220
eingesetzt, begleitet durch

868
00:30:15.220 --> 00:30:17.820
Ethikräte oder interdisziplinäre

869
00:30:17.820 --> 00:30:19.420
Aufsichtsgremien.

870
00:30:19.420 --> 00:30:21.060
Globale Zusammenarbeit wird

871
00:30:21.060 --> 00:30:23.260
zentral, denn KI macht nicht

872
00:30:23.260 --> 00:30:25.100
an Landesgrenzen halt.

873
00:30:25.100 --> 00:30:26.940
Institutionen wie UNESCO

874
00:30:26.940 --> 00:30:29.180
oder die EU spielen dabei

875
00:30:29.180 --> 00:30:30.700
eine koordinierende Rolle.

876
00:30:32.630 --> 00:30:33.550
Abschließend zwei

877
00:30:33.550 --> 00:30:35.190
Zukunftsszenarien.

878
00:30:35.190 --> 00:30:36.950
Diese Szenarien sollen keine

879
00:30:36.950 --> 00:30:38.750
fertige Prognose sein, sondern

880
00:30:38.750 --> 00:30:40.390
zum Nachdenken anregen.

881
00:30:41.110 --> 00:30:43.510
Schule 2035,

882
00:30:43.510 --> 00:30:45.270
jedes Schulkind arbeitet mit

883
00:30:45.270 --> 00:30:47.670
einer individuellen Lern KI.

884
00:30:47.670 --> 00:30:49.910
Lehrkräfte steuern gezielt nach,

885
00:30:49.910 --> 00:30:51.230
geben Feedback und

886
00:30:51.230 --> 00:30:53.350
fördern soziale Kompetenzen.

887
00:30:53.350 --> 00:30:55.590
Die KI protokolliert Lernstände

888
00:30:55.590 --> 00:30:57.510
datensparsam und ermöglicht

889
00:30:57.510 --> 00:30:58.790
individuelle Förderung.

890
00:30:59.660 --> 00:31:01.060
Die Schule definiert klare

891
00:31:01.060 --> 00:31:02.260
Regeln für den KI

892
00:31:02.260 --> 00:31:04.140
Einsatz und berücksichtigt

893
00:31:04.140 --> 00:31:05.580
Feedback der Lernenden.

894
00:31:07.980 --> 00:31:11.020
Verwaltung 2035,

895
00:31:11.020 --> 00:31:12.940
eine KI unterstützt die Bearbeitung

896
00:31:12.940 --> 00:31:14.900
administrativer Vorgänge in

897
00:31:14.900 --> 00:31:16.780
der öffentlichen Verwaltung.

898
00:31:16.780 --> 00:31:18.460
Sie analysiert Anträge,

899
00:31:18.460 --> 00:31:20.620
erkennt Standardfälle, schlägt

900
00:31:20.620 --> 00:31:22.380
Zuständigkeiten vor und

901
00:31:22.380 --> 00:31:23.740
erstellt Entwürfe für

902
00:31:23.740 --> 00:31:25.760
Bescheide oder Rückmeldungen.

903
00:31:25.760 --> 00:31:26.800
Die Entscheidung trifft

904
00:31:26.800 --> 00:31:28.400
weiterhin ein Mensch.

905
00:31:28.400 --> 00:31:30.080
Transparenz, Fairness und

906
00:31:30.080 --> 00:31:32.200
Datenschutz sind durch begleitende

907
00:31:32.200 --> 00:31:34.480
Prüfverfahren gewährleistet.

908
00:31:34.480 --> 00:31:36.720
Komplexe oder strittige Fälle

909
00:31:36.720 --> 00:31:38.640
erhalten mehr Aufmerksamkeit,

910
00:31:38.640 --> 00:31:41.040
während Routinearbeiten zunehmend

911
00:31:41.040 --> 00:31:42.880
automatisiert abgewickelt werden.

912
00:31:43.920 --> 00:31:47.240
Diese Visionen wenn wir KI aktiv

913
00:31:47.240 --> 00:31:49.120
und wertebasiert gestalten,

914
00:31:49.120 --> 00:31:51.080
kann sie ein hilfreiches Werkzeug

915
00:31:51.080 --> 00:31:52.080
für mehr Gerechtigkeit,

916
00:31:52.800 --> 00:31:54.560
Effizienz und Teilhabe sein.

917
00:31:55.120 --> 00:31:57.760
Wandel ist sicher, doch wie dieser

918
00:31:57.760 --> 00:31:59.920
aussieht, liegt in unserer Hand.

919
00:32:06.720 --> 00:32:08.840
Zum Abschluss noch eine kleine KI

920
00:32:08.840 --> 00:32:11.520
Anekdote, die zeigt, wie weit oder

921
00:32:11.520 --> 00:32:13.680
eben nicht weit wir bereit sind,

922
00:32:13.680 --> 00:32:16.000
KI Verantwortung zu übertragen.

923
00:32:18.330 --> 00:32:20.490
Wussten sie, dass in den USA

924
00:32:20.490 --> 00:32:22.010
tatsächlich mal ein KI

925
00:32:22.010 --> 00:32:23.610
Bürgermeister kandidiert hat?

926
00:32:24.250 --> 00:32:26.010
2024

927
00:32:26.010 --> 00:32:28.090
trat in einer Stadt in Wyoming ein

928
00:32:28.090 --> 00:32:30.410
Bibliothekar zur Bürgermeisterwahl

929
00:32:30.410 --> 00:32:31.450
mit dem Versprechen

930
00:32:31.450 --> 00:32:33.170
an, alle Entscheidungen von

931
00:32:33.170 --> 00:32:35.530
einer KI treffen zu lassen.

932
00:32:35.530 --> 00:32:37.210
Er hatte einen ChatGPT

933
00:32:37.210 --> 00:32:39.610
basierten Bot namens VIC

934
00:32:39.610 --> 00:32:41.170
Abkürzung für virtual

935
00:32:41.170 --> 00:32:42.690
Integrated Citizen

936
00:32:42.690 --> 00:32:43.980
programmiert, der als

937
00:32:43.980 --> 00:32:45.340
künstlicher Bürgermeister

938
00:32:45.340 --> 00:32:47.220
fungieren sollte, während er

939
00:32:47.220 --> 00:32:48.900
selbst nur als ausführendes

940
00:32:48.900 --> 00:32:50.260
Organ dienen würde.

941
00:32:50.260 --> 00:32:52.900
Wick sollte datengetriebene

942
00:32:52.900 --> 00:32:55.020
Einsichten und innovative Lösungen

943
00:32:55.020 --> 00:32:57.100
liefern, und der Mensch würde

944
00:32:57.100 --> 00:32:58.180
nur noch unterschreiben.

945
00:32:58.820 --> 00:33:00.740
Eine kühne Idee.

946
00:33:00.740 --> 00:33:02.180
Das Wahlergebnis war

947
00:33:02.180 --> 00:33:03.620
jedoch eindeutig.

948
00:33:03.620 --> 00:33:05.260
Der Kandidat erhielt gerade

949
00:33:05.260 --> 00:33:07.620
einmal 300 siebenundzwanzig

950
00:33:07.620 --> 00:33:09.540
von über Stimmen.

951
00:33:10.330 --> 00:33:11.930
Die Wähler waren nicht bereit,

952
00:33:11.930 --> 00:33:12.970
ihre Stadt von einem

953
00:33:12.970 --> 00:33:15.050
Chatbot regieren zu lassen.

954
00:33:15.050 --> 00:33:16.890
Der KI Bürgermeister

955
00:33:16.890 --> 00:33:18.890
scheiterte also krachend.

956
00:33:18.890 --> 00:33:20.290
Der echte Amtsinhaber

957
00:33:20.290 --> 00:33:21.610
behielt seinen Posten.

958
00:33:22.330 --> 00:33:24.410
Diese kuriose Geschichte zeigt

959
00:33:24.410 --> 00:33:27.330
mit einem ganz so schnell

960
00:33:27.330 --> 00:33:29.450
übernimmt KI nicht die Macht.

961
00:33:29.450 --> 00:33:30.690
Denn zum Glück haben wir

962
00:33:30.690 --> 00:33:32.690
Menschen da ein Wort mitzureden

963
00:33:32.690 --> 00:33:34.490
oder eine Stimme abzugeben.

964
00:33:36.580 --> 00:33:39.460
In diesem KI kann viel,

965
00:33:39.460 --> 00:33:41.020
aber am Ende bestimmen

966
00:33:41.020 --> 00:33:43.140
wir, wie weit wir gehen.

967
00:33:43.140 --> 00:33:45.140
Eine Prise Skepsis und Humor

968
00:33:45.140 --> 00:33:46.380
im Umgang mit solchen

969
00:33:46.380 --> 00:33:48.500
Zukunftsvisionen schadet nicht.

970
00:33:48.500 --> 00:33:50.340
Und manchmal hält uns so eine

971
00:33:50.340 --> 00:33:52.420
Anekdote den Spiegel vor.

972
00:33:52.420 --> 00:33:54.300
Sie erinnert uns daran, dass

973
00:33:54.300 --> 00:33:55.860
Technikbegeisterung ohne

974
00:33:55.860 --> 00:33:57.460
kritisches Hinterfragen

975
00:33:57.460 --> 00:33:59.620
leicht ins Absurde abdriften kann.
